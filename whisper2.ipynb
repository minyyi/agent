{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba444c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets[audio]\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from datasets[audio]) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from datasets[audio]) (2.2.3)\n",
      "Collecting xxhash (from datasets[audio])\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets[audio])\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting librosa (from datasets[audio])\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting soxr>=0.4.0 (from datasets[audio])\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiohttp-3.12.7-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: psutil in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading frozenlist-1.6.2-cp311-cp311-win_amd64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->datasets[audio])\n",
      "  Using cached cffi-1.17.1-cp311-cp311-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->datasets[audio])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.0.0->accelerate)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Collecting audioread>=2.1.9 (from librosa->datasets[audio])\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->datasets[audio])\n",
      "  Downloading numba-0.61.2-cp311-cp311-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting scipy>=1.6.0 (from librosa->datasets[audio])\n",
      "  Downloading scipy-1.15.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa->datasets[audio])\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting joblib>=1.0 (from librosa->datasets[audio])\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from librosa->datasets[audio]) (5.2.1)\n",
      "Collecting pooch>=1.1 (from librosa->datasets[audio])\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->datasets[audio])\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->datasets[audio])\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->datasets[audio])\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.3.8)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa->datasets[audio])\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\ai_prompt\\workspace\\ai_agent_work\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.5 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.5 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 15.4 MB/s eta 0:00:00\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Downloading aiohttp-3.12.7-cp311-cp311-win_amd64.whl (449 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.2-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 12.2 MB/s eta 0:00:00\n",
      "Using cached cffi-1.17.1-cp311-cp311-win_amd64.whl (181 kB)\n",
      "Downloading soxr-0.5.0.post1-cp311-cp311-win_amd64.whl (166 kB)\n",
      "Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/212.5 MB 7.0 MB/s eta 0:00:31\n",
      "    --------------------------------------- 5.2/212.5 MB 13.3 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.9/212.5 MB 12.5 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 11.0/212.5 MB 13.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 14.7/212.5 MB 13.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 17.8/212.5 MB 14.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 21.5/212.5 MB 14.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 25.7/212.5 MB 15.4 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 28.8/212.5 MB 15.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 32.0/212.5 MB 15.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 35.7/212.5 MB 15.6 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 40.9/212.5 MB 16.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 46.7/212.5 MB 17.4 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 51.9/212.5 MB 17.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 56.9/212.5 MB 18.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 63.2/212.5 MB 19.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 71.0/212.5 MB 20.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 76.3/212.5 MB 20.5 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 82.6/212.5 MB 21.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 88.3/212.5 MB 21.4 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 92.3/212.5 MB 21.4 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 96.2/212.5 MB 21.3 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 100.9/212.5 MB 21.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 106.4/212.5 MB 21.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 110.1/212.5 MB 21.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 113.0/212.5 MB 21.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 117.4/212.5 MB 21.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 121.4/212.5 MB 21.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 124.0/212.5 MB 20.9 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 127.1/212.5 MB 20.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 134.7/212.5 MB 21.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 143.7/212.5 MB 22.0 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 149.2/212.5 MB 22.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 153.9/212.5 MB 22.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 158.3/212.5 MB 22.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 163.1/212.5 MB 22.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 168.3/212.5 MB 22.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 173.3/212.5 MB 22.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 177.2/212.5 MB 22.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 180.6/212.5 MB 22.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 184.3/212.5 MB 21.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 186.9/212.5 MB 21.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 188.7/212.5 MB 21.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 191.1/212.5 MB 21.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.0/212.5 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 195.8/212.5 MB 20.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 197.4/212.5 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 199.5/212.5 MB 20.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 201.3/212.5 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 201.9/212.5 MB 19.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.0/212.5 MB 19.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  210.8/212.5 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 19.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 27.6 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl (74 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 80.3 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.9/30.3 MB 18.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 8.1/30.3 MB 20.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 12.1/30.3 MB 19.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.0/30.3 MB 19.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 20.7/30.3 MB 20.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.9/30.3 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.8/30.3 MB 20.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 20.0 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 23.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 20.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.3-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.4/41.2 MB 16.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.5/41.2 MB 10.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.2/41.2 MB 15.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 13.4/41.2 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 18.1/41.2 MB 17.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.9/41.2 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.2/41.2 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.6/41.2 MB 15.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.0/41.2 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.5/41.2 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.9/41.2 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/41.2 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 28.1 MB/s eta 0:00:00\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: mpmath, xxhash, threadpoolctl, sympy, soxr, scipy, safetensors, regex, pyyaml, pycparser, propcache, networkx, multidict, msgpack, llvmlite, lazy_loader, joblib, fsspec, frozenlist, filelock, dill, audioread, aiohappyeyeballs, yarl, torch, scikit-learn, pooch, numba, multiprocess, huggingface-hub, cffi, aiosignal, tokenizers, soundfile, aiohttp, accelerate, transformers, librosa, datasets\n",
      "\n",
      "   ----------------------------------------  0/39 [mpmath]\n",
      "   ----------------------------------------  0/39 [mpmath]\n",
      "   ----------------------------------------  0/39 [mpmath]\n",
      "   ----------------------------------------  0/39 [mpmath]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   --- ------------------------------------  3/39 [sympy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ----- ----------------------------------  5/39 [scipy]\n",
      "   ------ ---------------------------------  6/39 [safetensors]\n",
      "   -------- -------------------------------  8/39 [pyyaml]\n",
      "   --------- ------------------------------  9/39 [pycparser]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   ----------- ---------------------------- 11/39 [networkx]\n",
      "   -------------- ------------------------- 14/39 [llvmlite]\n",
      "   -------------- ------------------------- 14/39 [llvmlite]\n",
      "   -------------- ------------------------- 14/39 [llvmlite]\n",
      "   -------------- ------------------------- 14/39 [llvmlite]\n",
      "   ---------------- ----------------------- 16/39 [joblib]\n",
      "   ---------------- ----------------------- 16/39 [joblib]\n",
      "   ---------------- ----------------------- 16/39 [joblib]\n",
      "   ---------------- ----------------------- 16/39 [joblib]\n",
      "   ----------------- ---------------------- 17/39 [fsspec]\n",
      "   ----------------- ---------------------- 17/39 [fsspec]\n",
      "   ----------------- ---------------------- 17/39 [fsspec]\n",
      "   ------------------- -------------------- 19/39 [filelock]\n",
      "   -------------------- ------------------- 20/39 [dill]\n",
      "   -------------------- ------------------- 20/39 [dill]\n",
      "   --------------------- ------------------ 21/39 [audioread]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------ --------------- 24/39 [torch]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   ------------------------- -------------- 25/39 [scikit-learn]\n",
      "   -------------------------- ------------- 26/39 [pooch]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   --------------------------- ------------ 27/39 [numba]\n",
      "   ---------------------------- ----------- 28/39 [multiprocess]\n",
      "   ---------------------------- ----------- 28/39 [multiprocess]\n",
      "   ---------------------------- ----------- 28/39 [multiprocess]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ----------------------------- ---------- 29/39 [huggingface-hub]\n",
      "   ------------------------------ --------- 30/39 [cffi]\n",
      "   -------------------------------- ------- 32/39 [tokenizers]\n",
      "   ---------------------------------- ----- 34/39 [aiohttp]\n",
      "   ---------------------------------- ----- 34/39 [aiohttp]\n",
      "   ---------------------------------- ----- 34/39 [aiohttp]\n",
      "   ---------------------------------- ----- 34/39 [aiohttp]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ----------------------------------- ---- 35/39 [accelerate]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------ --- 36/39 [transformers]\n",
      "   ------------------------------------- -- 37/39 [librosa]\n",
      "   ------------------------------------- -- 37/39 [librosa]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   -------------------------------------- - 38/39 [datasets]\n",
      "   ---------------------------------------- 39/39 [datasets]\n",
      "\n",
      "Successfully installed accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.7 aiosignal-1.3.2 audioread-3.0.1 cffi-1.17.1 datasets-3.6.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.6.2 fsspec-2025.3.0 huggingface-hub-0.32.4 joblib-1.5.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 mpmath-1.3.0 msgpack-1.1.0 multidict-6.4.4 multiprocess-0.70.16 networkx-3.5 numba-0.61.2 pooch-1.8.2 propcache-0.3.1 pycparser-2.22 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 soundfile-0.13.1 soxr-0.5.0.post1 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 transformers-4.52.4 xxhash-3.5.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade transformers datasets[audio] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf5849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\github\\gpt_agent_2025_easyspub\\ffmpeg-2025-02-10-full_build\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59aaf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ffmpeg was not found but is required to load audio files from filename",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\audio_utils.py:34\u001b[39m, in \u001b[36mffmpeg_read\u001b[39m\u001b[34m(bpayload, sampling_rate)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffmpeg_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ffmpeg_process:\n\u001b[32m     35\u001b[39m         output_stream = ffmpeg_process.communicate(bpayload)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2]     ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# sample = dataset[0][\"audio\"]\u001b[39;00m\n\u001b[32m     31\u001b[39m sample = \u001b[33m\"\u001b[39m\u001b[33m./audio/lsy_audio_2023_58s.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m result = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(result[\"text\"])\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:295\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    236\u001b[39m     inputs: Union[np.ndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    237\u001b[39m     **kwargs,\n\u001b[32m    238\u001b[39m ):\n\u001b[32m    239\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    documentation for more information.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m \u001b[33;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1423\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1428\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:186\u001b[39m, in \u001b[36mPipelineChunkIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mself\u001b[39m.subiterator = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator), **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     processed = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubiterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.subiterator = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator), **\u001b[38;5;28mself\u001b[39m.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:375\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[39m\u001b[34m(self, inputs, chunk_length_s, stride_length_s)\u001b[39m\n\u001b[32m    372\u001b[39m             inputs = f.read()\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     inputs = \u001b[43mffmpeg_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m stride = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    378\u001b[39m extra = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\audio_utils.py:37\u001b[39m, in \u001b[36mffmpeg_read\u001b[39m\u001b[34m(bpayload, sampling_rate)\u001b[39m\n\u001b[32m     35\u001b[39m         output_stream = ffmpeg_process.communicate(bpayload)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mffmpeg was not found but is required to load audio files from filename\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n\u001b[32m     38\u001b[39m out_bytes = output_stream[\u001b[32m0\u001b[39m]\n\u001b[32m     39\u001b[39m audio = np.frombuffer(out_bytes, np.float32)\n",
      "\u001b[31mValueError\u001b[39m: ffmpeg was not found but is required to load audio files from filename"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True,   #   \n",
    "    chunk_length_s=10,  #   10 r\n",
    "    stride_length_s=2,  # 2   \n",
    ") \n",
    "\n",
    "# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "# sample = dataset[0][\"audio\"]\n",
    "sample = \"./audio/lsy_audio_2023_58s.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "# print(result[\"text\"])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe35024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../audio/lsy_audio_2023_58s.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# sample = dataset[0][\"audio\"]\u001b[39;00m\n\u001b[32m     31\u001b[39m sample = \u001b[33m\"\u001b[39m\u001b[33m../audio/lsy_audio_2023_58s.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m result = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(result[\"text\"])\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:295\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    236\u001b[39m     inputs: Union[np.ndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    237\u001b[39m     **kwargs,\n\u001b[32m    238\u001b[39m ):\n\u001b[32m    239\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    documentation for more information.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m \u001b[33;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1423\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1428\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:186\u001b[39m, in \u001b[36mPipelineChunkIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mself\u001b[39m.subiterator = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator), **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     processed = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubiterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.subiterator = \u001b[38;5;28mself\u001b[39m.infer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator), **\u001b[38;5;28mself\u001b[39m.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI_Prompt\\workspace\\ai_agent_work\\venv\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:371\u001b[39m, in \u001b[36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[39m\u001b[34m(self, inputs, chunk_length_s, stride_length_s)\u001b[39m\n\u001b[32m    369\u001b[39m         inputs = requests.get(inputs).content\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    372\u001b[39m             inputs = f.read()\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../audio/lsy_audio_2023_58s.mp3'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True,   #   \n",
    "    chunk_length_s=10,  #   10 r\n",
    "    stride_length_s=2,  # 2   \n",
    ") \n",
    "\n",
    "# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "# sample = dataset[0][\"audio\"]\n",
    "sample = \"../audio/lsy_audio_2023_58s.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "# print(result[\"text\"])\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
